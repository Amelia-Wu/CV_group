1. 读取图片，根据train.csv, “左图片”为要判断的图片，“右图片”们为20个候选图片， 看看是否能够找到正确的与做图片看起来相似的图片，（取前两个概率最高的右图片，看正确的答案有没有在里面， 有则分类成功）
2. 读取图片的代码，要右图片的数量可调
3. **进入神经网络前，可以自己做特征提取，比如用opencv的sift算法，提取图片的特征，然后用神经网络对（对自己弄的特征/特征加原图（怎么结合）/原图）做分类** 
4. 样本是一对一对的图片，和一对一对的标签，标签是0或1，0表示不相似，1表示相似

## CNN网络结构：
**特征提取部分：** 每个CNN都接收一幅图片作为输入，并输出该图片的特征向量。这两个CNN可以是任何类型的预训练模型，如VGG、ResNet等。

**比较部分：** 这部分接收来自两个CNN的特征向量，并计算它们之间的差异。这可以通过计算欧氏距离、余弦相似度或其他度量来实现。

**分类部分：** 这部分接收比较部分的输出，并进行最终的分类。这可以是一个简单的线性分类器，也可以是一个更复杂的神经网络。

## Transformer：
提取特征部分换成  Transformer 预训练模型

使用Transformer的Encoder作为特征提取器：我们可以使用Transformer的Encoder（例如，视觉Transformer）来从每幅图像中提取特征表示。这种类型的模型也常被称为图像编码器1。每个图像都会被单独输入到一个Encoder中，然后输出一个特征向量。这个特征向量捕捉了图像的重要视觉信息。

使用Transformer的Decoder进行特征融合：在某些情况下，我们可能希望将两个图像的特征融合在一起，然后输入到一个Decoder中进行处理。例如，在语义图像分割任务中，我们可以使用一个基于Transformer的Encoder-Decoder结构来进行特征融合和空间信息恢复

https://arxiv.org/pdf/2106.04108.pdf （语义图像分割）

## 残差网络


# 其他想法：
- 将两个图片合成一个图片作为输入（像素拼接/对应像素运算（加减）），分类



